{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       https://www2.daad.de/deutschland/studienangebo...\n",
       "1       https://www2.daad.de/deutschland/studienangebo...\n",
       "2       https://www2.daad.de/deutschland/studienangebo...\n",
       "3       https://www2.daad.de/deutschland/studienangebo...\n",
       "4       https://www2.daad.de/deutschland/studienangebo...\n",
       "                              ...                        \n",
       "1509    https://www2.daad.de/deutschland/studienangebo...\n",
       "1510    https://www2.daad.de/deutschland/studienangebo...\n",
       "1511    https://www2.daad.de/deutschland/studienangebo...\n",
       "1512    https://www2.daad.de/deutschland/studienangebo...\n",
       "1513    https://www2.daad.de/deutschland/studienangebo...\n",
       "Name: Detail Link, Length: 1514, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./archive/daad_international_master_programs.csv\")\n",
    "df['Detail Link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new variable 'link' with the updated values\n",
    "link = df['Detail Link'] + \"#tab_registration\"\n",
    "\n",
    "# Display the new variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www2.daad.de/deutschland/studienangebote/international-programmes/en/detail/4770/#tab_registration\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the data from index 1 to 10 into a new variable\n",
    "new_link = link.iloc[1:3]  # Note: iloc is exclusive of the last index\n",
    "\n",
    "# Display the new variable\n",
    "print(new_link[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Url ===\n",
      "https://www2.daad.de/deutschland/studienangebote/international-programmes/en/detail/7065/#tab_registration\n",
      "\n",
      "=== Academic Requirements ===\n",
      "No data found\n",
      "\n",
      "=== Language Requirements ===\n",
      "No data found\n",
      "\n",
      "=== Application Deadline ===\n",
      "No data found\n",
      "\n",
      "=== Submit Application ===\n",
      "No data found\n",
      "\n",
      "Data has been saved to university_requirements.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def scrape_university_requirements(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Initialize empty strings for each requirement\n",
    "        academic_req = \"\"\n",
    "        language_req = \"\"\n",
    "        deadline_req = \"\"\n",
    "        submit_req = \"\"\n",
    "\n",
    "        # Find all dt elements\n",
    "        dt_elements = soup.find_all('dt', class_='c-description-list__content')\n",
    "        \n",
    "        for dt in dt_elements:\n",
    "            header_text = dt.get_text(strip=True)\n",
    "            dd = dt.find_next('dd', class_='c-description-list__content mb-0')\n",
    "            \n",
    "            if dd:\n",
    "                # Extract all text from dd tag and its children\n",
    "                content = []\n",
    "                \n",
    "                # Process each child element\n",
    "                for element in dd.descendants:\n",
    "                    if isinstance(element, str) and element.strip():\n",
    "                        # If it's a text node and not empty\n",
    "                        content.append(element.strip())\n",
    "                    elif element.name == 'br':\n",
    "                        # Add line break for <br> tags\n",
    "                        content.append('\\n')\n",
    "                    elif element.name == 'li':\n",
    "                        # Add bullet points for list items\n",
    "                        content.append(f\"• {element.get_text().strip()}\")\n",
    "                \n",
    "                # Join all content with newlines\n",
    "                full_content = '\\n'.join(filter(None, content))\n",
    "                \n",
    "                # Assign content to appropriate variable\n",
    "                if header_text == 'Academic admission requirements':\n",
    "                    academic_req = full_content\n",
    "                elif header_text == 'Language requirements':\n",
    "                    language_req = full_content\n",
    "                elif header_text == 'Application deadline':\n",
    "                    deadline_req = full_content\n",
    "                elif header_text == 'Submit application to':\n",
    "                    submit_req = full_content\n",
    "\n",
    "        # Create DataFrame with URL column\n",
    "        df = pd.DataFrame({\n",
    "            'url': [url],\n",
    "            'academic_requirements': [academic_req],\n",
    "            'language_requirements': [language_req],\n",
    "            'application_deadline': [deadline_req],\n",
    "            'submit_application': [submit_req]\n",
    "        })\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "url = new_link[2]\n",
    "results = scrape_university_requirements(url)\n",
    "\n",
    "\n",
    "if results is not None:\n",
    "    # Print each section with clear separators\n",
    "    for column in results.columns:\n",
    "        print(f\"\\n=== {column.replace('_', ' ').title()} ===\")\n",
    "        content = results[column].iloc[0]\n",
    "        if content:\n",
    "            print(content)\n",
    "        else:\n",
    "            print(\"No data found\")\n",
    "\n",
    "    # Save to CSV\n",
    "    results.to_csv('university_requirements.csv', index=False)\n",
    "    print(\"\\nData has been saved to university_requirements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing URL: https://www2.daad.de/deutschland/studienangebote/international-programmes/en/detail/4770/#tab_registration\n",
      "\n",
      "=== Url ===\n",
      "https://www2.daad.de/deutschland/studienangebote/international-programmes/en/detail/4770/#tab_registration\n",
      "\n",
      "=== Academic Requirements ===\n",
      "BSc degree in Mathematics\n",
      "\n",
      "=== Language Requirements ===\n",
      "English:\n",
      "Accepted certificate:\n",
      "• IELTS min. 5.5\n",
      "IELTS min. 5.5\n",
      "• TOEFL iBT (Internet-based test): min. 72 points\n",
      "TOEFL iBT (Internet-based test): min. 72 points\n",
      "• TOEFL PBT: min. 543 points\n",
      "TOEFL PBT: min. 543 points\n",
      "• TOEFL ITP Level 1: min. 543 points\n",
      "TOEFL ITP Level 1: min. 543 points\n",
      "• Cambridge Preliminary English Test + Result Distinction (PET)\n",
      "Cambridge Preliminary English Test + Result Distinction (PET)\n",
      "• Cambridge First Certificate in English: Grade B or C (FCE)\n",
      "Cambridge First Certificate in English: Grade B or C (FCE)\n",
      "• Cambridge English: Business Vantage (BEC Vantage), Legal (ILEC), Financial (ICFE)\n",
      "Cambridge English: Business Vantage (BEC Vantage), Legal (ILEC), Financial (ICFE)\n",
      "• Cambridge IGCSE: 1st or 2nd Language on average B2\n",
      "Cambridge IGCSE: 1st or 2nd Language on average B2\n",
      "• Pearson PTE Academic: min. 59 points\n",
      "Pearson PTE Academic: min. 59 points\n",
      "• TOEIC: Listening and Reading Test min. 785 points, Speaking Test min. 160 points, Writing Test min. 150 points\n",
      "TOEIC: Listening and Reading Test min. 785 points, Speaking Test min. 160 points, Writing Test min. 150 points\n",
      "• telc B2\n",
      "telc B2\n",
      "• UNIcert II\n",
      "UNIcert II\n",
      "• Study in English studies\n",
      "Study in English studies\n",
      "• completed degree with English as the language of instruction\n",
      "completed degree with English as the language of instruction\n",
      "• proof of professional qualification as interpreter/translator\n",
      "proof of professional qualification as interpreter/translator\n",
      "Applicants from countries with English as official/educational or native language are not required to submit proof of English language proficiency with their application.\n",
      "German:\n",
      "Although not compulsory, basic knowledge of German is recommended at the beginning of the programme. Courses to obtain the required level of German language (A2) are included within the curriculum for non-native speakers. Students providing a certificate of A2 level (CEFR) may choose advanced language courses or subject studies.\n",
      "\n",
      "=== Application Deadline ===\n",
      "15 July for the following winter semester\n",
      "\n",
      "\n",
      "15 January for the following summer semester\n",
      "All documents (see course website) have to be submitted by the deadline via\n",
      "uni-assist\n",
      ". Please start your application as early as possible.\n",
      "International applicants are very welcome!\n",
      "\n",
      "=== Submit Application ===\n",
      "Applications may be submitted online at\n",
      "https://www.uni-assist.de/en\n",
      ".\n",
      "It is not necessary to send certified copies. Please note that uni-assist must receive all application documents by the application deadline.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Processing URL: https://www2.daad.de/deutschland/studienangebote/international-programmes/en/detail/7065/#tab_registration\n",
      "\n",
      "=== Url ===\n",
      "https://www2.daad.de/deutschland/studienangebote/international-programmes/en/detail/7065/#tab_registration\n",
      "\n",
      "=== Academic Requirements ===\n",
      "No data found\n",
      "\n",
      "=== Language Requirements ===\n",
      "No data found\n",
      "\n",
      "=== Application Deadline ===\n",
      "No data found\n",
      "\n",
      "=== Submit Application ===\n",
      "No data found\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "All data has been saved to university_requirements.csv\n",
      "Total URLs processed: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scrape_university_requirements(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Initialize empty strings for each requirement\n",
    "        academic_req = \"\"\n",
    "        language_req = \"\"\n",
    "        deadline_req = \"\"\n",
    "        submit_req = \"\"\n",
    "\n",
    "        # Find all dt elements\n",
    "        dt_elements = soup.find_all('dt', class_='c-description-list__content')\n",
    "        \n",
    "        for dt in dt_elements:\n",
    "            header_text = dt.get_text(strip=True)\n",
    "            dd = dt.find_next('dd', class_='c-description-list__content mb-0')\n",
    "            \n",
    "            if dd:\n",
    "                # Extract all text from dd tag and its children\n",
    "                content = []\n",
    "                \n",
    "                # Process each child element\n",
    "                for element in dd.descendants:\n",
    "                    if isinstance(element, str) and element.strip():\n",
    "                        # If it's a text node and not empty\n",
    "                        content.append(element.strip())\n",
    "                    elif element.name == 'br':\n",
    "                        # Add line break for <br> tags\n",
    "                        content.append('\\n')\n",
    "                    elif element.name == 'li':\n",
    "                        # Add bullet points for list items\n",
    "                        content.append(f\"• {element.get_text().strip()}\")\n",
    "                \n",
    "                # Join all content with newlines\n",
    "                full_content = '\\n'.join(filter(None, content))\n",
    "                \n",
    "                # Assign content to appropriate variable\n",
    "                if header_text == 'Academic admission requirements':\n",
    "                    academic_req = full_content\n",
    "                elif header_text == 'Language requirements':\n",
    "                    language_req = full_content\n",
    "                elif header_text == 'Application deadline':\n",
    "                    deadline_req = full_content\n",
    "                elif header_text == 'Submit application to':\n",
    "                    submit_req = full_content\n",
    "\n",
    "        # Create DataFrame with URL column\n",
    "        df = pd.DataFrame({\n",
    "            'url': [url],\n",
    "            'academic_requirements': [academic_req],\n",
    "            'language_requirements': [language_req],\n",
    "            'application_deadline': [deadline_req],\n",
    "            'submit_application': [submit_req]\n",
    "        })\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for URL {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# List to store all results\n",
    "all_results = []\n",
    "\n",
    "# Process each URL\n",
    "for url in new_link:\n",
    "    print(f\"\\nProcessing URL: {url}\")\n",
    "    result = scrape_university_requirements(url)\n",
    "    if result is not None:\n",
    "        all_results.append(result)\n",
    "        # Print data for current URL\n",
    "        for column in result.columns:\n",
    "            print(f\"\\n=== {column.replace('_', ' ').title()} ===\")\n",
    "            content = result[column].iloc[0]\n",
    "            if content:\n",
    "                print(content)\n",
    "            else:\n",
    "                print(\"No data found\")\n",
    "    print(\"-\" * 80)  # Print separator between URLs\n",
    "\n",
    "# Combine all results\n",
    "if all_results:\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    final_df.to_csv('university_requirements.csv', index=False)\n",
    "    print(\"\\nAll data has been saved to university_requirements.csv\")\n",
    "    print(f\"Total URLs processed: {len(all_results)}\")\n",
    "else:\n",
    "    print(\"\\nNo data was successfully scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
